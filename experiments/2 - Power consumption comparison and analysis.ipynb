{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43262eb9-390c-4c07-a2aa-e09656ed8dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4a77a-dd5d-49cf-ab27-8b67b20586c6",
   "metadata": {},
   "source": [
    "#### Auxiliary functions used to generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3926ca3-e268-4e37-bfe4-87a77412412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison_metric(competitors: dict[str, pd.DataFrame],\n",
    "                           reference_competitor : str,\n",
    "                           column : str,\n",
    "                           title_plot : str,\n",
    "                           y_label : str,\n",
    "                           x_limit : tuple[float, float],\n",
    "                           save_path : str) :\n",
    "    ''' \n",
    "    This function generates a plot that compares various scoring plugin under some metric as the % of requested\n",
    "    GPU cluster resources increases.\n",
    "    '''\n",
    "\n",
    "    # Set the font size for all plot elements\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    \n",
    "    # Plotting\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "    line_styles = ['-', '--', ':', '-.'] * 2\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'orange']\n",
    "    ax1.set_prop_cycle(cycler('linestyle', line_styles) + cycler('color', colors))\n",
    "    \n",
    "    for k, v in competitors.items() :\n",
    "        if k == reference_competitor: continue\n",
    "        ax1.plot(v.index, v[column], label=k)\n",
    "    ax1.plot(competitors[reference_competitor].index, competitors[reference_competitor][column], label=reference_competitor)\n",
    "\n",
    "    ax1.set_xlim(x_limit)\n",
    "    ax1.set_xlabel('% GPU cluster capacity requested by arrived pods')\n",
    "    ax1.set_ylabel(y_label)\n",
    "    ax1.legend(fontsize='small')\n",
    "    # plt.title(title_plot)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(save_path, format='pdf')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c9cd3-1c66-4945-9f52-55fc84d3601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_failed_relative(competitors_sched: dict[str, pd.DataFrame], \n",
    "                         reference_competitor : str, column_sched : str, title_plot : str) :\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    line_styles = ['-', '--', ':', '-.'] * 2\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'orange']\n",
    "    ax1.set_prop_cycle(cycler('linestyle', line_styles) + cycler('color', colors))\n",
    "    \n",
    "    reference = competitors_sched[reference_competitor]\n",
    "    for k, v in competitors_sched.items() :\n",
    "        if k == reference_competitor: continue\n",
    "        ax1.plot(v.index, v[column_sched] - reference[column_sched], label=k)\n",
    "    \n",
    "    ax1.set_xlabel('% GPU cluster capacity requested by arrived pods')\n",
    "    ax1.set_ylabel(f'Difference w.r.t. {reference_competitor}')\n",
    "    ax1.legend()\n",
    "    plt.title(title_plot)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b59d1e-642c-48b1-8081-a40793ba6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energy_savings(competitors_pwr: dict[str, pd.DataFrame], \n",
    "                        reference_competitor : str, \n",
    "                        column_power : str, \n",
    "                        title_plot : str,\n",
    "                        save_path : str) :\n",
    "\n",
    "    # Set the font size for all plot elements\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "    line_styles = ['-', '--', ':', '-.'] * 2\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'orange']\n",
    "    ax1.set_prop_cycle(cycler('linestyle', line_styles) + cycler('color', colors))\n",
    "    \n",
    "    reference = competitors_pwr[reference_competitor]\n",
    "    for k, v in competitors_pwr.items() :\n",
    "        if k == reference_competitor: continue\n",
    "        ax1.plot(v.index, (reference[column_power] - v[column_power]) / reference[column_power] * 100, label=k)\n",
    "\n",
    "    ax1.set_xlim((0, 1))\n",
    "    ax1.set_xlabel('% GPU cluster capacity requested by arrived pods')\n",
    "    ax1.set_ylabel(f'Percentage power savings w.r.t. {reference_competitor}')\n",
    "    ax1.legend(fontsize='small')\n",
    "    # plt.title(title_plot)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(save_path, format='pdf')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4902ea0-d27a-494d-bdd1-166f1b5c66a5",
   "metadata": {},
   "source": [
    "### Retrieve power consumption and task scheduling information from the logs of the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7101db-67dc-4a4f-ac53-8eb500f90d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries where the results will be stored.\n",
    "df_pwr_dict = {}\n",
    "df_frag_dict = {}\n",
    "df_sched_pod_dict = {}\n",
    "\n",
    "DATADIR = \"./2024_0606\"\n",
    "data = Path(DATADIR)\n",
    "\n",
    "fileDirs = sorted([x for x in data.iterdir() if x.is_dir()])\n",
    "for fdir in fileDirs:\n",
    "    df_pwr_dict[fdir.name] = {}\n",
    "    df_frag_dict[fdir.name] = {}\n",
    "    df_sched_pod_dict[fdir.name] = {}\n",
    "\n",
    "    policyDirs = sorted([x for x in fdir.iterdir() if x.is_dir()])\n",
    "    for pdir in policyDirs:\n",
    "        print(f\"Processing data for set of experiments: {fdir.name}.{pdir.name}\")\n",
    "        \n",
    "        tuneDirs = sorted([x for x in pdir.iterdir() if x.is_dir()])\n",
    "        for tdir in tuneDirs:\n",
    "            seedDirs = sorted([x for x in tdir.iterdir() if x.is_dir()])\n",
    "            for sdir in seedDirs:\n",
    "                pwrfile = sdir / 'analysis_pwr.csv'\n",
    "                grep = sdir / 'analysis_grep.out'\n",
    "                alloc = sdir / 'analysis_allo.csv'\n",
    "                schedfile = sdir / 'analysis_cdol.csv'\n",
    "                fragfile = sdir / 'analysis_frag.csv'\n",
    "\n",
    "                # Retrieve the total GPU cluster capacity (in millis).\n",
    "                try:\n",
    "                    with open(grep, 'r') as file:\n",
    "                        content = file.read()  # Read the entire file into a string\n",
    "                        # Find the position of 'allocation: ' in the content\n",
    "                        start_idx = content.find('MilliGpu: ')\n",
    "                        if start_idx != -1:\n",
    "                            # Find the end of the line\n",
    "                            end_idx = content.find('\\n', start_idx)\n",
    "                            # Extract the allocation part\n",
    "                            selection = content[start_idx:end_idx]\n",
    "                            # Extract the integer part by splitting the string\n",
    "                            allocation_value = int(selection.split(\"/\")[1].split(\")\")[0])\n",
    "                        else:\n",
    "                            raise Exception(\"MilliGpu cluster info not found. Error!\\n\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"ERROR grep analysis: %s\\n\" % (e))\n",
    "\n",
    "                # print(f\"Total GPU cluster capacity: {allocation_value}\\n\")\n",
    "\n",
    "                \n",
    "                \n",
    "                ### Collect telemetry about the GPU workload (in millis) that the cluster has received. ###\n",
    "                try:\n",
    "                    df_allo = pd.read_csv(alloc)\n",
    "                    df_allo.rename(columns = lambda x: x.split('-')[-1], inplace=True)\n",
    "                    cum_gpu_allo = df_allo.loc[:, 'arrived_gpu_milli'] / allocation_value\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"ERROR alloc analysis: %s\\n\" % (e))\n",
    "\n",
    "                # print(df_allo)\n",
    "                # sys.exit() # DEBUG!\n",
    "                \n",
    "\n",
    "                \n",
    "                # Set up the index for GPU requests received by the cluster.\n",
    "                new_index = np.arange(0, 1.005, 0.005)\n",
    "\n",
    "                ### Collect telemetry about power consumption. ###\n",
    "                try:\n",
    "                    df_pwr = pd.read_csv(pwrfile)\n",
    "                    df_pwr.rename(columns = lambda x: x.split('-')[-1], inplace=True)\n",
    "                    df_pwr[\"cumulative_workload\"] = cum_gpu_allo\n",
    "                    df_pwr.set_index(\"cumulative_workload\", inplace = True)\n",
    "\n",
    "                    # Remove rows with duplicated index entries, keeping only the first entry for each group of duplicates.\n",
    "                    # Then, add the entries in new_index in df_pwr's existing index via a union.\n",
    "                    # Then, reindex and interpolate the missing values.\n",
    "                    # Finally, keep only the rows whose index entries are present in new_index (i.e., the regularly spaced ones).\n",
    "                    df_pwr = df_pwr[~df_pwr.index.duplicated(keep='first')]\n",
    "                    df_pwr = df_pwr.reindex(df_pwr.index.union(new_index)).interpolate(method='linear').ffill().bfill()\n",
    "                    df_pwr = df_pwr.loc[new_index]\n",
    "                    if df_pwr.isna().any().any(): \n",
    "                        # print(df_pwr[df_pwr.isna().any(axis=1)])\n",
    "                        raise Exception(\"dataframe contains NaNs!\\n\")\n",
    "                        \n",
    "                    df_pwr_dict[fdir.name].setdefault(pdir.name, list()).append(df_pwr)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"ERROR power analysis: %s\\n\" % (e))\n",
    "\n",
    "                # print(df_pwr)\n",
    "                # sys.exit() # DEBUG!\n",
    "\n",
    "\n",
    "\n",
    "                ### Collect telemetry about power consumption. ###\n",
    "                try:\n",
    "                    df_frag = pd.read_csv(fragfile)\n",
    "                    df_frag.rename(columns = lambda x: x.split('-')[-1], inplace=True)\n",
    "                    df_frag = df_frag[[\"origin_ratio\"]]\n",
    "                    df_frag[\"cumulative_workload\"] = cum_gpu_allo\n",
    "                    df_frag.set_index(\"cumulative_workload\", inplace = True)\n",
    "\n",
    "                    # Remove rows with duplicated index entries, keeping only the first entry for each group of duplicates.\n",
    "                    # Then, add the entries in new_index in df_pwr's existing index via a union.\n",
    "                    # Then, reindex and interpolate the missing values.\n",
    "                    # Finally, keep only the rows whose index entries are present in new_index (i.e., the regularly spaced ones).\n",
    "                    df_frag = df_frag[~df_frag.index.duplicated(keep='first')]\n",
    "                    df_frag = df_frag.reindex(df_frag.index.union(new_index)).interpolate(method='linear').ffill().bfill()\n",
    "                    df_frag = df_frag.loc[new_index]\n",
    "                    if df_frag.isna().any().any(): \n",
    "                        # print(df_frag[df_frag.isna().any(axis=1)])\n",
    "                        raise Exception(\"dataframe contains NaNs!\\n\")\n",
    "                        \n",
    "                    df_frag_dict[fdir.name].setdefault(pdir.name, list()).append(df_frag)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"ERROR fragmentation analysis: %s\\n\" % (e))\n",
    "\n",
    "                #print(df_frag)\n",
    "                #sys.exit() # DEBUG!\n",
    "                \n",
    "\n",
    "                \n",
    "                ### Collect telemetry about pods that the cluster failed to schedule. ###\n",
    "                try:\n",
    "                    df_sched_pod = pd.read_csv(schedfile)\n",
    "                    df_sched_pod.rename(columns = lambda x: x.split('-')[-1], inplace=True)\n",
    "                    df_sched_pod = df_sched_pod[['event']]\n",
    "                    df_sched_pod[\"issued_pods\"] = df_sched_pod.index + 1\n",
    "                    df_sched_pod[\"cumulative_workload\"] = cum_gpu_allo\n",
    "                    df_sched_pod['event'] = 1 * (df_sched_pod['event'] == 'failed')\n",
    "                    df_sched_pod['event'] = df_sched_pod['event'].cumsum()\n",
    "                    df_sched_pod.rename(columns = {'event' : 'failed_pods_cumsum'}, inplace = True)\n",
    "                    df_sched_pod['arrived_gpu_milli'] = df_allo['arrived_gpu_milli']\n",
    "                    df_sched_pod['used_gpu_milli'] = df_allo['used_gpu_milli']\n",
    "                    df_sched_pod['successful_pods'] = df_sched_pod[\"issued_pods\"] - df_sched_pod[\"failed_pods_cumsum\"]\n",
    "                    df_sched_pod.set_index(\"cumulative_workload\", inplace = True)\n",
    "\n",
    "                    df_sched_pod = df_sched_pod[~df_sched_pod.index.duplicated(keep='first')]\n",
    "                    df_sched_pod = df_sched_pod.reindex(df_sched_pod.index.union(new_index)).interpolate(method='linear').ffill().bfill()\n",
    "                    df_sched_pod = df_sched_pod.loc[new_index]\n",
    "                    if df_sched_pod.isna().any().any(): \n",
    "                        raise Exception(\"dataframe contains NaNs!\\n\")\n",
    "                    \n",
    "                    df_sched_pod_dict[fdir.name].setdefault(pdir.name, list()).append(df_sched_pod)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(\"ERROR scheduling analysis: %s\\n\" % (e))\n",
    "\n",
    "                # print(df_sched_pod)\n",
    "                # sys.exit() # DEBUG!\n",
    "\n",
    "\n",
    "# display(df_pwr_dict.keys())\n",
    "# display(df_pwr_dict)\n",
    "# display(df_sched_pod_dict.keys())\n",
    "# display(df_sched_pod_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64894368-5825-48ad-9505-7fc1e301c4fa",
   "metadata": {},
   "source": [
    "#### Compute the average power consumption and number of failed plugins within each score plugin's set of runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092758e9-9c8f-4fe4-9a28-ac38b4bb52a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of competitors to exclude to avoid cluttering the plots too much.\n",
    "set_remove_competitors = {'01-Random',\n",
    "                          #'02-DotProd',\n",
    "                          #'03-GpuClustering',\n",
    "                          #'04-GpuPacking',\n",
    "                          #'05-BestFit',\n",
    "                          '08-PWR_500_FGD_500', \n",
    "                          '13-PWR_25_FGD_975', \n",
    "                          '09-PWR_300_FGD_700', \n",
    "                          '10-PWR_200_FGD_800',}\n",
    "\n",
    "\n",
    "# Compute the average power consumption for each score plugin.\n",
    "dict_pwr_final_res = {}\n",
    "for k in df_pwr_dict.keys() :\n",
    "    dict_pwr_final_res[k] = {}\n",
    "    for k2 in df_pwr_dict[k].keys() :\n",
    "        if k2 in set_remove_competitors : continue\n",
    "        print(f\"Computing cluster power consumption mean for level ({k},{k2}) ({len(df_pwr_dict[k][k2])} repetitions found)\")\n",
    "        dict_pwr_final_res[k][k2] = sum(df_pwr_dict[k][k2]) / len(df_pwr_dict[k][k2])\n",
    "\n",
    "\n",
    "# Compute the average power consumption for each score plugin.\n",
    "dict_frag_final_res = {}\n",
    "for k in df_frag_dict.keys() :\n",
    "    dict_frag_final_res[k] = {}\n",
    "    for k2 in df_frag_dict[k].keys() :\n",
    "        if k2 in set_remove_competitors : continue\n",
    "        print(f\"Computing fragmentation mean for level ({k},{k2}) ({len(df_frag_dict[k][k2])} repetitions found)\")\n",
    "        dict_frag_final_res[k][k2] = sum(df_frag_dict[k][k2]) / len(df_frag_dict[k][k2])\n",
    "\n",
    "\n",
    "# Compute the average failed pod for each score plugin.\n",
    "dict_sched_final_res = {}\n",
    "for k in df_sched_pod_dict.keys() :\n",
    "    dict_sched_final_res[k] = {}\n",
    "    for k2 in df_sched_pod_dict[k].keys() :\n",
    "        if k2 in set_remove_competitors : continue\n",
    "        print(f\"Computing mean # of pods that have failed to schedule for level ({k},{k2}) ({len(df_sched_pod_dict[k][k2])} repetitions found)\")\n",
    "        dict_sched_final_res[k][k2] = sum(df_sched_pod_dict[k][k2]) / len(df_sched_pod_dict[k][k2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe8c9d6-0836-4f2c-8d15-7a828af424fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(dict_pwr_final_res.keys())\n",
    "# display(dict_pwr_final_res['openb_pod_list_default']['01-Random'])\n",
    "# display(dict_sched_final_res.keys())\n",
    "# display(dict_sched_final_res['openb_pod_list_default']['01-Random'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050460d7-99ac-4705-8ffa-558f43de58c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautify the names of the policies for the plots.\n",
    "for k_level in dict_pwr_final_res.keys() :\n",
    "    dict_pwr_final_res[k_level] = {key.split('-')[1]: value for key, value in dict_pwr_final_res[k_level].items()}\n",
    "    dict_sched_final_res[k_level] = {key.split('-')[1]: value for key, value in dict_sched_final_res[k_level].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdafe4a-4a43-4c2d-bb53-fba969e9b64e",
   "metadata": {},
   "source": [
    "# Measuring efficiency overall score (not included in the article, for now)\n",
    "\n",
    "The overall efficiency score is computed as: 0.5 $\\cdot$ (usage efficiency + energy efficiency),\n",
    "\n",
    "where:\n",
    "\n",
    "* \"usage efficiency\" is the ratio between the allocated and requested GPU resources (expressed in millis);\n",
    "* \"energy efficiency\" is the ratio between the allocated GPU resources and the cluster GPU power consumption.\n",
    "\n",
    "Note: both efficiencies then get normalized in [0,1], where values closer to 1 indicate better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb9fa61-1a30-488b-833f-c5bb0a34b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_efficiency = {}\n",
    "for level in dict_pwr_final_res.keys() :\n",
    "    \n",
    "    df_efficiency[level] = {}\n",
    "    max_energy_efficiency = 0\n",
    "    \n",
    "    # Compute energy and usage efficiency.\n",
    "    for policy in dict_pwr_final_res[level].keys() :\n",
    "        # print(f'{level} - {policy}')\n",
    "\n",
    "        # display(dict_pwr_final_res[level][policy])\n",
    "        # display(dict_sched_final_res[level][policy])\n",
    "\n",
    "        df_efficiency[level][policy] = pd.DataFrame(index = dict_pwr_final_res[level][policy].index)\n",
    "\n",
    "        # Usage efficiency is computed as the ratio between successfully allocated GPU resources and requested GPU resources.\n",
    "        # This comes already normalized in [0,1]\n",
    "        df_efficiency[level][policy]['usage_efficiency'] = dict_sched_final_res[level][policy]['used_gpu_milli']/ dict_sched_final_res[level][policy]['arrived_gpu_milli']\n",
    "\n",
    "        # Power efficiency is computed as the ratio between the amount of used GPU resources (in millis) vs\n",
    "        # the cluster GPU power consumption.\n",
    "        df_efficiency[level][policy]['energy_efficiency'] = dict_sched_final_res[level][policy]['used_gpu_milli'] / dict_pwr_final_res[level][policy]['power_cluster_GPU']\n",
    "        \n",
    "        # Update the maximum energy efficiency found among the various competitors if needed.\n",
    "        max_energy_efficiency = max(max_energy_efficiency, df_efficiency[level][policy]['energy_efficiency'].max())\n",
    "        \n",
    "        # display(df_efficiency[level][policy])\n",
    "        # display(max_energy_efficiency)\n",
    "\n",
    "    # Normalize the power efficiency.\n",
    "    for policy in df_efficiency[level].keys() :\n",
    "        df_efficiency[level][policy]['energy_efficiency'] /= max_energy_efficiency\n",
    "\n",
    "    # Compute the overall efficiency score\n",
    "    for policy in df_efficiency[level].keys() :\n",
    "        df_efficiency[level][policy]['overall_efficiency'] = 0.5 * (df_efficiency[level][policy]['energy_efficiency'] + df_efficiency[level][policy]['usage_efficiency'])\n",
    "        \n",
    "    # display(df_efficiency[level][policy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41471cfd-ceb7-45fa-8b35-a024bac462cb",
   "metadata": {},
   "source": [
    "# Generation of plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fa93c9-d3a4-4cb8-bf3a-182f4a23b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the directory of the plots, if needed.\n",
    "dir_plots = './energy_aware_plots/'\n",
    "if not os.path.exists(dir_plots): os.makedirs(dir_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb8839f-4558-4337-a6ad-6e8e987ce5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_competitor = 'FGD'\n",
    "for level in dict_pwr_final_res.keys() :\n",
    "\n",
    "    print(f\"Generating plots for {level}...\")\n",
    "    \n",
    "    # Plot the energy savings achieved with some competitor w.r.t. the reference competitor.\n",
    "    # X-axis represents the arrived workloads in % of GPU resources available in the cluster. \n",
    "    plot_energy_savings(dict_pwr_final_res[level], reference_competitor, \n",
    "                        \"power_cluster\", \n",
    "                        f\"CPU+GPU power savings vs {reference_competitor} (set experiments: {level})\",\n",
    "                        dir_plots + \"pwrsaving_\" + level + '.pdf')\n",
    "\n",
    "    plot_comparison_metric(df_efficiency[level],\n",
    "                           reference_competitor,\n",
    "                           'usage_efficiency',\n",
    "                           f\"GPU Allocated vs Requested resource ratio (set experiments: {level})\",\n",
    "                           'GPU Allocated vs Requested resource ratio',\n",
    "                           (0.8,1),\n",
    "                           dir_plots + \"gpuocc_\" + level + '.pdf')\n",
    "\n",
    "\n",
    "\n",
    "    #### Ignored (for now) ####s\n",
    "    if False :\n",
    "        plot_comparison_metric(df_efficiency[level],\n",
    "                               reference_competitor,\n",
    "                               'energy_efficiency',\n",
    "                               f\"GPU Allocated Resources per watt (normalized) (set experiments: {level})\",\n",
    "                               'GPU Allocated Resources (in millis) per watt (normalized)')\n",
    "\n",
    "    if False :\n",
    "        plot_comparison_metric(df_efficiency[level],\n",
    "                               reference_competitor,\n",
    "                               'overall_efficiency',\n",
    "                               f\"Overall efficiency (set experiments: {level})\",\n",
    "                               'Overall Efficiency')\n",
    "\n",
    "\n",
    "    # Plot the difference between number of pods that failed with some competitor w.r.t. the reference competitor.\n",
    "    # X-axis represents the arrived workloads in % of GPU resources available in the cluster. \n",
    "    if False :\n",
    "        plot_failed_relative(dict_sched_final_res[level], reference_competitor, \n",
    "                             \"failed_pods_cumsum\", f\"Comparison of failed pods vs {reference_competitor} (set experiments: {level})\")\n",
    "\n",
    "    # Plot the overall cluster energy consumption w.r.t. the arrived workloads in % of GPU resources available in the cluster.\n",
    "    if False :\n",
    "        plot_comparison_metric(dict_pwr_final_res[level],\n",
    "                               \"power_cluster\",\n",
    "                               f\"Overall cluster energy consumption (set experiments: {level})\",\n",
    "                               \"Watts\")\n",
    "\n",
    "\n",
    "    # Plot the cluster fragmentation ratio w.r.t. the arrived workloads in % of GPU resources available in the cluster. \n",
    "    if False :\n",
    "        plot_comparison_metric(dict_frag_final_res[level], \n",
    "                               \"origin_ratio\",\n",
    "                               f\"Cluster fragmentation ratio (set experiments: {level})\",\n",
    "                               \"Cluster fragmentation ratio\")\n",
    "\n",
    "\n",
    "    # Plot the GPU cluster energy consumption w.r.t. the arrived workloads in % of GPU resources available in the cluster.\n",
    "    if False :\n",
    "        plot_comparison_metric(dict_pwr_final_res[level],\n",
    "                               \"power_cluster_GPU\",\n",
    "                               f'GPU cluster energy consumption (set experiments: {level})',\n",
    "                               \"Watts\")\n",
    "        plot_energy_savings(dict_pwr_final_res[level], reference_competitor, \n",
    "                            \"power_cluster_GPU\", f\"GPU power savings vs {reference_competitor} (set experiments: {level})\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Plot the CPU cluster energy consumption w.r.t. the arrived workloads in % of GPU resources available in the cluster.\n",
    "    if False :\n",
    "        plot_comparison_metric(dict_pwr_final_res[level],\n",
    "                               \"power_cluster_CPU\",\n",
    "                               f'CPU cluster energy consumption (set experiments: {level})',\n",
    "                               \"Watts\")\n",
    "        plot_energy_savings(dict_pwr_final_res[level], reference_competitor, \n",
    "                            \"power_cluster_CPU\", f\"CPU cluster power savings vs {reference_competitor} (set experiments: {level})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
