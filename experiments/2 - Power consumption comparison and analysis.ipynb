{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43262eb9-390c-4c07-a2aa-e09656ed8dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4a77a-dd5d-49cf-ab27-8b67b20586c6",
   "metadata": {},
   "source": [
    "#### Auxiliary functions used to generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3926ca3-e268-4e37-bfe4-87a77412412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison_metric(competitors: dict[str, pd.DataFrame],\n",
    "                           column : str,\n",
    "                           title_plot : str,\n",
    "                           y_label : str) :\n",
    "    ''' \n",
    "    This function generates a plot that compares various scoring plugin under some metric as the % of requested\n",
    "    GPU cluster resources increases.\n",
    "    '''\n",
    "    \n",
    "    # Plotting\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    for k, v in competitors.items() : \n",
    "        ax1.plot(v.index, v[column], label=k)\n",
    "    ax1.set_xlabel('% GPU cluster capacity requested by arrived pods')\n",
    "    ax1.set_ylabel(y_label)\n",
    "    \n",
    "    # Legends\n",
    "    ax1.legend()\n",
    "    \n",
    "    plt.title(title_plot)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b59d1e-642c-48b1-8081-a40793ba6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energy_savings(competitors_pwr: dict[str, pd.DataFrame], \n",
    "                        reference_competitor : str, column_power : str, title_plot : str) :\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    reference = competitors_pwr[reference_competitor]\n",
    "    for k, v in competitors_pwr.items() :\n",
    "        if k == reference_competitor: continue\n",
    "        ax1.plot(v.index, (reference[column_power] - v[column_power]) / reference[column_power] * 100, label=k)\n",
    "    ax1.set_xlabel('% GPU cluster capacity requested by arrived pods')\n",
    "    ax1.set_ylabel('% power savings')\n",
    "    \n",
    "    # Legends\n",
    "    ax1.legend()\n",
    "    \n",
    "    plt.title(title_plot)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4902ea0-d27a-494d-bdd1-166f1b5c66a5",
   "metadata": {},
   "source": [
    "### Retrieve power consumption and failed pods data from the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7101db-67dc-4a4f-ac53-8eb500f90d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries where the results will be stored.\n",
    "df_pwr_dict = {}\n",
    "df_sched_pod_dict = {}\n",
    "\n",
    "DATADIR = \"./2024_0606\"\n",
    "data = Path(DATADIR)\n",
    "\n",
    "fileDirs = sorted([x for x in data.iterdir() if x.is_dir()])\n",
    "for fdir in fileDirs:\n",
    "    df_pwr_dict[fdir.name] = {}\n",
    "    df_sched_pod_dict[fdir.name] = {}\n",
    "\n",
    "    policyDirs = sorted([x for x in fdir.iterdir() if x.is_dir()])\n",
    "    for pdir in policyDirs:            \n",
    "        tuneDirs = sorted([x for x in pdir.iterdir() if x.is_dir()])\n",
    "        for tdir in tuneDirs:\n",
    "            seedDirs = sorted([x for x in tdir.iterdir() if x.is_dir()])\n",
    "            for sdir in seedDirs:\n",
    "                pwrfile = sdir / 'analysis_pwr.csv'\n",
    "                grep = sdir / 'analysis_grep.out'\n",
    "                alloc = sdir / 'analysis_allo.csv'\n",
    "                schedfile = sdir / 'analysis_cdol.csv'\n",
    "\n",
    "\n",
    "                # Retrieve the total GPU cluster capacity (in millis).\n",
    "                try:\n",
    "                    with open(grep, 'r') as file:\n",
    "                        content = file.read()  # Read the entire file into a string\n",
    "                        # Find the position of 'allocation: ' in the content\n",
    "                        start_idx = content.find('MilliGpu: ')\n",
    "                        if start_idx != -1:\n",
    "                            # Find the end of the line\n",
    "                            end_idx = content.find('\\n', start_idx)\n",
    "                            # Extract the allocation part\n",
    "                            selection = content[start_idx:end_idx]\n",
    "                            # Extract the integer part by splitting the string\n",
    "                            allocation_value = int(selection.split(\"/\")[1].split(\")\")[0])\n",
    "                        else:\n",
    "                            raise Exception(\"MilliGpu cluster info not found. Error!\\n\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"ERROR grep analysis: %s\\n\" % (e))\n",
    "\n",
    "                # print(f\"Total GPU cluster capacity: {allocation_value}\\n\")\n",
    "\n",
    "                \n",
    "                \n",
    "                ### Collect telemetry about the GPU workload (in millis) that the cluster has received. ###\n",
    "                try:\n",
    "                    df_allo = pd.read_csv(alloc)\n",
    "                    df_allo.rename(columns = lambda x: x.split('-')[-1], inplace=True)\n",
    "                    df_allo = df_allo.loc[:, 'arrived_gpu_milli'] / allocation_value\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"ERROR alloc analysis: %s\\n\" % (e))\n",
    "\n",
    "                # print(df_allo)\n",
    "                # sys.exit() # DEBUG!\n",
    "                \n",
    "\n",
    "                \n",
    "                # Set up the index for GPU requests received by the cluster.\n",
    "                new_index = np.arange(0, 1.205, 0.005)\n",
    "\n",
    "                ### Collect telemetry about power consumption. ###\n",
    "                try:\n",
    "                    df_pwr = pd.read_csv(pwrfile)\n",
    "                    df_pwr.rename(columns = lambda x: x.split('-')[-1], inplace=True)\n",
    "                    df_pwr[\"cumulative_workload\"] = df_allo\n",
    "                    df_pwr.set_index(\"cumulative_workload\", inplace = True)\n",
    "\n",
    "                    # Remove rows with duplicated index entries, keeping only the first entry for each group of duplicates.\n",
    "                    # Then, add the entries in new_index in df_pwr's existing index via a union.\n",
    "                    # Then, reindex and interpolate the missing values.\n",
    "                    # Finally, keep only the rows whose index entries are present in new_index (i.e., the regularly spaced ones).\n",
    "                    df_pwr = df_pwr[~df_pwr.index.duplicated(keep='first')]\n",
    "                    df_pwr = df_pwr.reindex(df_pwr.index.union(new_index)).interpolate(method='linear').ffill().bfill()\n",
    "                    df_pwr = df_pwr.loc[new_index]\n",
    "                    if df_pwr.isna().any().any(): \n",
    "                        # print(df_pwr[df_pwr.isna().any(axis=1)])\n",
    "                        raise Exception(\"dataframe contains NaNs!\\n\")\n",
    "                        \n",
    "                    df_pwr_dict[fdir.name].setdefault(pdir.name, list()).append(df_pwr)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"ERROR power analysis: %s\\n\" % (e))\n",
    "\n",
    "                # print(df_pwr)\n",
    "                # sys.exit() # DEBUG!\n",
    "                \n",
    "\n",
    "                \n",
    "                ### Collect telemetry about pods that the cluster failed to schedule. ###\n",
    "                try:\n",
    "                    df_sched_pod = pd.read_csv(schedfile)\n",
    "                    df_sched_pod.rename(columns = lambda x: x.split('-')[-1], inplace=True)\n",
    "                    df_sched_pod = df_sched_pod[['event']]\n",
    "                    df_sched_pod[\"cumulative_workload\"] = df_allo\n",
    "                    df_sched_pod['event'] = 1 * (df_sched_pod['event'] == 'failed')\n",
    "                    df_sched_pod['event'] = df_sched_pod['event'].cumsum()\n",
    "                    df_sched_pod.set_index(\"cumulative_workload\", inplace = True)\n",
    "\n",
    "                    df_sched_pod = df_sched_pod[~df_sched_pod.index.duplicated(keep='first')]\n",
    "                    df_sched_pod = df_sched_pod.reindex(df_sched_pod.index.union(new_index)).interpolate(method='linear').ffill().bfill()\n",
    "                    df_sched_pod = df_sched_pod.loc[new_index]\n",
    "                    if df_sched_pod.isna().any().any(): \n",
    "                        raise Exception(\"dataframe contains NaNs!\\n\")\n",
    "                    \n",
    "                    df_sched_pod_dict[fdir.name].setdefault(pdir.name, list()).append(df_sched_pod)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(\"ERROR scheduling analysis: %s\\n\" % (e))\n",
    "\n",
    "                # print(df_sched_pod)\n",
    "                # sys.exit() # DEBUG!\n",
    "\n",
    "\n",
    "# display(df_pwr_dict.keys())\n",
    "# display(df_pwr_dict)\n",
    "# display(df_sched_pod_dict.keys())\n",
    "# display(df_sched_pod_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64894368-5825-48ad-9505-7fc1e301c4fa",
   "metadata": {},
   "source": [
    "#### Compute the average power consumption and number of failed plugins within each score plugin's set of runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092758e9-9c8f-4fe4-9a28-ac38b4bb52a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average power consumption for each score plugin.\n",
    "dict_pwr_final_res = {}\n",
    "for k in df_pwr_dict.keys() :\n",
    "    dict_pwr_final_res[k] = {}\n",
    "    for k2 in df_pwr_dict[k].keys() :\n",
    "        print(f\"Computing cluster power consumption mean for level ({k},{k2}) ({len(df_pwr_dict[k][k2])} reps)\")\n",
    "        dict_pwr_final_res[k][k2] = sum(df_pwr_dict[k][k2]) / len(df_pwr_dict[k][k2])\n",
    "\n",
    "\n",
    "# Compute the average failed pod for each score plugin.\n",
    "dict_sched_final_res = {}\n",
    "for k in df_sched_pod_dict.keys() :\n",
    "    dict_sched_final_res[k] = {}\n",
    "    for k2 in df_sched_pod_dict[k].keys() :\n",
    "        print(f\"Computing mean of pods that have failed to schedule for level ({k},{k2}) ({len(df_sched_pod_dict[k][k2])} reps)\")\n",
    "        dict_sched_final_res[k][k2] = sum(df_sched_pod_dict[k][k2]) / len(df_sched_pod_dict[k][k2])\n",
    "\n",
    "    \n",
    "# display(dict_pwr_final_res.keys())\n",
    "# display(dict_pwr_final_res)\n",
    "# display(dict_sched_final_res.keys())\n",
    "# display(dict_sched_final_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41471cfd-ceb7-45fa-8b35-a024bac462cb",
   "metadata": {},
   "source": [
    "### Generation of power consumption plots: overall, GPU only, and CPU only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb8839f-4558-4337-a6ad-6e8e987ce5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_competitor = '06-FGD'\n",
    "for level in dict_pwr_final_res.keys() :\n",
    "    # Plot the number of pods that failed to be scheduled w.r.t. the arrived workloads in % of GPU resources available in the cluster. \n",
    "    plot_comparison_metric(dict_sched_final_res[level], \n",
    "                       \"event\",\n",
    "                       f\"# of pods that failed to be scheduled (set experiments: {level})\",\n",
    "                       \"# failed pods\")\n",
    "\n",
    "    \n",
    "    # Plot the overall cluster energy consumption w.r.t. the arrived workloads in % of GPU resources available in the cluster.\n",
    "    plot_comparison_metric(dict_pwr_final_res[level],\n",
    "                           \"power_cluster\",\n",
    "                           f\"Overall cluster energy consumption (set experiments: {level})\",\n",
    "                           \"Watts\")\n",
    "    plot_energy_savings(dict_pwr_final_res[level], reference_competitor, \n",
    "                        \"power_cluster\", f\"Overall power savings vs {reference_competitor} (set experiments: {level})\")\n",
    "\n",
    "\n",
    "\n",
    "    # Plot the GPU cluster energy consumption w.r.t. the arrived workloads in % of GPU resources available in the cluster.\n",
    "    plot_comparison_metric(dict_pwr_final_res[level],\n",
    "                           \"power_cluster_GPU\",\n",
    "                           f'GPU cluster energy consumption (set experiments: {level})',\n",
    "                           \"Watts\")\n",
    "    plot_energy_savings(dict_pwr_final_res[level], reference_competitor, \n",
    "                        \"power_cluster_GPU\", f\"GPU power savings vs {reference_competitor} (set experiments: {level})\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Plot the CPU cluster energy consumption w.r.t. the arrived workloads in % of GPU resources available in the cluster.\n",
    "    #plot_comparison_metric(dict_pwr_final_res[level],\n",
    "    #                       \"power_cluster_CPU\",\n",
    "    #                       f'CPU cluster energy consumption (set experiments: {level})',\n",
    "    #                       \"Watts\")\n",
    "    #plot_energy_savings(dict_pwr_final_res[level], reference_competitor, \n",
    "    #                    \"power_cluster_CPU\", f\"CPU cluster power savings vs {reference_competitor} (set experiments: {level})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
